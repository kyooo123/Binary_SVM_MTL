{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Code that implements global, local and MTL binary classification using SVM type objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from scipy import linalg as LA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_prep_data():\n",
    "    # the folder should contain the features and labels for each task in seperate csv files.\n",
    "    # the name of the files should be feature_#task or label_#task.\n",
    "    # this function reads the data and returns two lists for features and labels. \n",
    "    # Inside length of the list is equal to the number of tasks and each item is a numpy ndarray\n",
    "    feature_list = glob.glob('features_*.csv')\n",
    "    label_list = glob.glob('labels_*.csv')\n",
    "    if (len(label_list)!=len(feature_list)):\n",
    "        assert('input diparity');\n",
    "    feature_list.sort()\n",
    "    label_list.sort()\n",
    "    X = []\n",
    "    Y = []\n",
    "    for f in feature_list:\n",
    "        X.append(np.genfromtxt(f, delimiter=','))\n",
    "    for el in label_list:\n",
    "        Y.append(np.genfromtxt(el, delimiter=','))\n",
    "    return X,Y\n",
    "def flatten_tasks(XX,YY):\n",
    "    # flattens the mt data for global modeling\n",
    "    X = XX[0]\n",
    "    Y = YY[0]\n",
    "    for t in range(len(XX)-1):\n",
    "        X = np.append(X,XX[t+1],0)\n",
    "        Y = np.append(Y,YY[t+1],0)\n",
    "    return X,Y\n",
    "\n",
    "def mt_data_split(X, y, perc, random_state):\n",
    "    m = len(X);\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for t in range(m):\n",
    "        Xt_train, Xt_test, yt_train, yt_test = train_test_split(X[t], y[t], test_size=perc)#, stratify=y[t])#, random_state=random_state)\n",
    "        X_train.append(Xt_train);\n",
    "        X_test.append(Xt_test);\n",
    "        y_train.append(yt_train);\n",
    "        y_test.append(yt_test);\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "XX,YY = read_prep_data()\n",
    "X,Y = flatten_tasks(XX,YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the class object for mtl classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class mtl:\n",
    "    def __init__(self, lam = 1.0 , max_outer_iter = 100, max_inner_iter = 10, max_local_iter = 1, random_seed = 3):\n",
    "        self.lam = lam # lambda: regularization parameter\n",
    "        self.max_outer_iter = max_outer_iter;\n",
    "        self.max_inner_iter = max_inner_iter;\n",
    "        self.max_local_iter = max_local_iter;\n",
    "        self.random_seed = random_seed;\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for t in range(self.num_tasks):\n",
    "            temp = np.sign(np.dot(X[t], self.model[:,t])).reshape((X[t].shape[0],1))\n",
    "            y.append(temp)\n",
    "        return y\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        yy = self.predict(X);\n",
    "        score_vec=np.zeros((self.num_tasks,1))\n",
    "        for t in range(self.num_tasks):\n",
    "            score_vec[t] = 1.0-np.sum(yy[t]!=y[t].reshape(y[t].shape[0],1))*1.0/(y[t].shape[0])\n",
    "        return score_vec\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # initialize\n",
    "        #np.random.seed(self.random_seed) # used for debugging\n",
    "        self.num_tasks = len(X);\n",
    "        self.d = X[0].shape[1]\n",
    "        d = self.d\n",
    "        m = self.num_tasks\n",
    "        self.Sigma = np.eye(m) * (1.0/m);\n",
    "        self.Omega = np.eye(m) * (1.0*m);\n",
    "        rho = 1.0\n",
    "        self.model = np.zeros((self.d,m))\n",
    "        self.alpha = []\n",
    "        W = self.model;\n",
    "        \n",
    "        self.n = []\n",
    "        self.totaln = 0\n",
    "        \n",
    "        for t in range(m):\n",
    "            temp = y[t].shape[0]\n",
    "            self.n.append(temp)\n",
    "            self.totaln = self.totaln + temp\n",
    "            self.alpha.append(np.zeros((temp,1)));\n",
    "        \n",
    "        size_x = np.zeros((max(self.n),m));\n",
    "        for t in range(m):\n",
    "            for i in range(self.n[t]):\n",
    "                curr_x = X[t][i, :].reshape((1,d));\n",
    "                size_x[i,t] = np.dot(curr_x,curr_x.transpose())\n",
    "        \n",
    "        \n",
    "        self.train_mse_iter = np.zeros((self.max_outer_iter,1));\n",
    "        for h in range(self.max_outer_iter):\n",
    "            self.train_mse_iter[h] = 1.0 - np.mean(self.score(X,y));\n",
    "            \n",
    "            ## update W\n",
    "            for hh in range(self.max_inner_iter):\n",
    "                deltaW = np.zeros((self.d, m));\n",
    "                deltaB = np.zeros((self.d, m));\n",
    "                \n",
    "                ## going over tasks\n",
    "                for t in range(m):\n",
    "                    alpha_t = self.alpha[t];\n",
    "                    curr_sig = self.Sigma[t,t];\n",
    "                    perm_t = np.random.permutation(self.n[t])\n",
    "                    local_iters_t = round(self.max_local_iter*self.n[t])\n",
    "                    \n",
    "                    for s in range(local_iters_t):\n",
    "                        idx = perm_t[(s%self.n[t])];\n",
    "                        # get current variables\n",
    "                        alpha_old = alpha_t[idx];\n",
    "                        curr_x = X[t][idx, :].reshape((1,d));\n",
    "                        curr_y = y[t][idx];\n",
    "                        size_xx = np.dot(curr_x,curr_x.transpose())\n",
    "                        update = (curr_y * np.dot(curr_x, (W[:,t] + rho * deltaW[:, t])));\n",
    "                        grad = self.lam * self.n[t] * (1.0 - update) / (curr_sig * rho * size_xx) + (alpha_old * curr_y);\n",
    "                        \n",
    "                        alpha_new = curr_y * max(0.0, min(1.0, grad));\n",
    "                        deltaW[:, t] = deltaW[:, t] + curr_sig * (alpha_new - alpha_old) * curr_x.transpose().squeeze()/ (self.lam * self.n[t]);\n",
    "                        deltaB[:, t] = deltaB[:, t] + (alpha_new - alpha_old) * curr_x.transpose().squeeze() / self.n[t];\n",
    "                        alpha_t[idx] = alpha_new;\n",
    "                            \n",
    "                # combine updates globally\n",
    "                for t in range(m):\n",
    "                    for tt in range(m):\n",
    "                        W[:, t] = W[:, t] + deltaB[:, tt] * self.Sigma[t, tt] * (1.0 / self.lam);\n",
    "        \n",
    "            \n",
    "    \n",
    "            # update the Sigmas\n",
    "            epsil = 0.0000001;\n",
    "            A = np.dot(W.transpose(),W)\n",
    "            D, V = LA.eigh(A)\n",
    "            D = (D * (D>epsil)) + epsil*(D<=epsil);           \n",
    "            sqm = np.sqrt(D)\n",
    "            s = np.sum(sqm)\n",
    "            sqm = sqm / s;\n",
    "            self.Sigma = (np.dot(np.dot(V, np.diag(sqm)), V.transpose()))\n",
    "            rho = max(np.sum(np.absolute(self.Sigma),0) / np.diag(self.Sigma));\n",
    "            \n",
    "        return self   \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"lam\": self.lam, \"max_outer_iter\": self.max_outer_iter, \"max_inner_iter\": self.max_inner_iter,\n",
    "                \"max_local_iter\": self.max_local_iter}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def data_split(self, X, y, perc, random_state):\n",
    "        self.num_tasks = len(X);\n",
    "        m = self.num_tasks\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        for t in range(m):\n",
    "            Xt_train, Xt_test, yt_train, yt_test = train_test_split(X[t], y[t], test_size=perc)#, random_state = random_state)\n",
    "            X_train.append(Xt_train);\n",
    "            X_test.append(Xt_test);\n",
    "            y_train.append(yt_train);\n",
    "            y_test.append(yt_test);\n",
    "        return X_train, X_test, y_train, y_test\n",
    "            \n",
    "    def cross_validate(self, X, y, folds = 5, lam_range=[.1,1.0,10.0], outer_iters_range = [1,10,20], inner_iters_range = [1,2], local_iters_range = [.1,1.0]):\n",
    "        #print('start running cv',flush=True)\n",
    "        el = len(lam_range);\n",
    "        oi = len(outer_iters_range)\n",
    "        ii = len(inner_iters_range)\n",
    "        eli = len(local_iters_range)\n",
    "        score_results = np.zeros((folds, el, oi ,ii, eli));\n",
    "        perc = 1.0/folds;\n",
    "        for f in range(folds):\n",
    "            random_state = np.random.randint(10000)\n",
    "            X_train, X_test, y_train, y_test = self.data_split(X, y, perc, random_state=random_state)\n",
    "            for el_it in range(el):\n",
    "                self.lam = lam_range[el_it]\n",
    "                for oi_it in range(oi):\n",
    "                    self.max_outer_iter = outer_iters_range[oi_it]\n",
    "                    for ii_it in range(ii):\n",
    "                        self.max_inner_iter = inner_iters_range[ii_it]\n",
    "                        for eli_it in range(eli):\n",
    "                            self.max_local_iter = local_iters_range[eli_it]\n",
    "                            self.fit(X_train, y_train)\n",
    "                            score_results[f,el_it,oi_it,ii_it, eli_it] = np.mean(self.score(X_test, y_test));\n",
    "        score_results_avg = np.mean(score_results, axis=0);\n",
    "        score_results_std = np.std(score_results, axis=0);\n",
    "        \n",
    "        # finding the best score\n",
    "        arg_max = np.argmax(score_results_avg);\n",
    "        args = np.unravel_index(arg_max, (el,oi,ii,eli))\n",
    "        \n",
    "        self.best_lam = lam_range[args[0]];\n",
    "        self.best_outer = outer_iters_range[args[1]];\n",
    "        self.best_inner = inner_iters_range[args[2]];\n",
    "        self.best_local = local_iters_range[args[3]];\n",
    "        \n",
    "        \n",
    "        self.lam = self.best_lam\n",
    "        self.max_outer_iter = self.best_outer\n",
    "        self.max_inner_iter = self.best_inner\n",
    "        self.max_local_iter = self.best_local\n",
    "        \n",
    "        self.fit(X,y)\n",
    "        return self.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code is for performing simple SVM that is used for local and global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class simple_svm:\n",
    "    def __init__(self, lam = 1.0, max_iter = 10, random_seed = 3):\n",
    "        self.lam = lam # lambda: regularization parameter\n",
    "        self.max_iter = max_iter;\n",
    "        self.random_seed = random_seed;\n",
    "    def fit(self, X,y):\n",
    "        # Simple function for solving an SVM with SDCA\n",
    "        # Used for local & global baselines\n",
    "        # At each point, the objective is g_i(w) = max(0,1-y_i x_i^T w). \n",
    "        # The overall objective is (1/N)*g_i(w) + (lambda/2)*||w||^2\n",
    "        # Inputs\n",
    "        # X: input training data\n",
    "        # y: output training data. should be -1,1's\n",
    "        # Output\n",
    "        # w: the learned model\n",
    "        \n",
    "        ## initialize\n",
    "        #np.random.seed(self.random_seed)\n",
    "        [n, d] = X.shape;\n",
    "        w = np.zeros((d, 1))\n",
    "        alpha = np.zeros((n, 1))\n",
    "        size_x = np.zeros((n,1))\n",
    "        for i in range(n):\n",
    "            curr_x = X[i, :].reshape((1,d));\n",
    "            size_x[i] = np.dot(curr_x,curr_x.transpose())\n",
    "        \n",
    "        for iter in range(self.max_iter):\n",
    "            ## update coordinates cyclically\n",
    "            for i in np.random.permutation(n):\n",
    "                # get current variables\n",
    "                alpha_old = alpha[i];\n",
    "                curr_x = X[i, :].reshape((1,d));\n",
    "                curr_y = y[i];\n",
    "\n",
    "                # calculate update\n",
    "                update = self.lam*n*(1.0 - (curr_y*np.dot(curr_x, w)))/size_x[i] + (alpha_old*curr_y)\n",
    "                # apply update\n",
    "                alpha_new = curr_y*max(0, min(1.0, update))\n",
    "                w = w + ((alpha_new - alpha_old) * curr_x.transpose() * (1.0 / (self.lam * n)));\n",
    "                alpha[i] = alpha_new;\n",
    "        \n",
    "        self.model = w\n",
    "        self.support_vector = alpha\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.model)).reshape((X.shape[0],1))\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return 1.0-np.sum(self.predict(X)!=y.reshape(len(y),1))*1.0/len(y)\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"lam\": self.lam, \"max_iter\": self.max_iter}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_local(Xtrain,ytrain, Xtest, ytest, cv = 5, lam_range = [1.0], max_iter_range = [10], tol_range = [.001]):\n",
    "    m = len(Xtrain)\n",
    "    results = np.zeros((m,1));\n",
    "    for t in range(m):\n",
    "        \n",
    "        \n",
    "        # doing the scikitlearn svm\n",
    "        nt = ytrain[t].shape[0]\n",
    "        C_list = []\n",
    "        for lam in lam_range:\n",
    "            C_list.append(1.0/(lam*nt))\n",
    "        param_grid = [{'C': C_list, 'tol': tol_range}]\n",
    "        classifier = SVC(C=1.0, kernel='linear')\n",
    "        train_cv = GridSearchCV(classifier, param_grid, cv = cv)\n",
    "        \n",
    "        # doing the simple svm\n",
    "        #classifier = simple_svm()\n",
    "        #param_grid = [{'lam': lam_range, 'max_iter':max_iter_range}]\n",
    "        #train_cv = GridSearchCV(classifier, param_grid, cv = cv)\n",
    "        \n",
    "        train_cv.fit(Xtrain[t],ytrain[t]);\n",
    "        results[t] = train_cv.score(Xtest[t],ytest[t]);\n",
    "        print('local method best params for task '+ str(t)+':')\n",
    "        print(train_cv.best_params_)\n",
    "    print('------')\n",
    "    return results\n",
    "\n",
    "def run_global(Xtrain,ytrain, Xtest, ytest, cv = 5, lam_range = [1.0], max_iter_range = [10], tol_range = [.001]):\n",
    "    m = len(Xtrain)\n",
    "    results = np.zeros((m,1))\n",
    "    Xf, yf = flatten_tasks(Xtrain,ytrain)\n",
    "    \n",
    "    # doing the scikitlearn SVC\n",
    "    n = yf.shape[0]\n",
    "    C_list = []\n",
    "    for lam in lam_range:\n",
    "        C_list.append(1.0/(lam*n))\n",
    "    param_grid = [{'C': C_list, 'tol': tol_range}]\n",
    "    classifier = SVC(C=1.0, kernel='linear')\n",
    "    train_cv = GridSearchCV(classifier, param_grid, cv = cv)\n",
    "    \n",
    "    # doing the simple svm\n",
    "    #classifier = simple_svm()\n",
    "    #param_grid = [{'lam': lam_range, 'max_iter':max_iter_range}]\n",
    "    #train_cv = GridSearchCV(classifier, param_grid, cv = cv)\n",
    "    \n",
    "    \n",
    "    train_cv.fit(Xf, yf);\n",
    "    print('global method best params:')\n",
    "    print(train_cv.best_params_)\n",
    "    print('----')\n",
    "    for t in range(m):\n",
    "        results[t] = train_cv.score(Xtest[t],ytest[t]);\n",
    "    return results\n",
    "\n",
    "def run_mtl(Xtrain, ytrain, Xtest, ytest, cv = 5, lam_range=[1.0],\n",
    "              outer_iters_range = [1], inner_iters_range = [1], \n",
    "              local_iters_range = [1.0]):\n",
    "    mtl_clf = mtl()\n",
    "    mtl_clf.cross_validate(Xtrain,ytrain, folds = cv, lam_range=lam_range,\n",
    "                           outer_iters_range = outer_iters_range, \n",
    "                           inner_iters_range = inner_iters_range,\n",
    "                           local_iters_range = local_iters_range)\n",
    "    print('mtl best parameters:')\n",
    "    print(['lambda:',mtl_clf.best_lam, 'outer:', mtl_clf.best_outer, 'inner:', mtl_clf.best_inner, 'local:', mtl_clf.best_local])\n",
    "    print('----')\n",
    "    return mtl_clf.score(Xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs the experiments by calling the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "test_perc = .9\n",
    "cv = 5;\n",
    "m = len(XX)\n",
    "np.random.seed(0)\n",
    "local_results = np.zeros((m,num_trials))\n",
    "global_results = np.zeros((m,num_trials))\n",
    "mtl_results = np.zeros((m,num_trials))\n",
    "\n",
    "for t in range(num_trials):\n",
    "    Xtrain, Xtest, Ytrain, Ytest = mt_data_split(XX, YY, test_perc, 10000*t+10000)\n",
    "\n",
    "    \n",
    "    # doing normalization an adding the bias term\n",
    "    for tasks in range(m):\n",
    "        scaler = StandardScaler(copy = False)\n",
    "        scaler.fit(Xtrain[tasks]);\n",
    "        scaler.transform(Xtrain[tasks], copy = False)\n",
    "        scaler.transform(Xtest[tasks], copy = False)\n",
    "        \n",
    "        # adding a relatively large constant (10) at the beginning (large value such that it cancels regularizing the bias)\n",
    "        all_ones = 10*np.ones((Xtrain[tasks].shape[0],1))\n",
    "        Xtrain[tasks] = np.append(all_ones,Xtrain[tasks],1);\n",
    "        \n",
    "        all_ones = 10*np.ones((Xtest[tasks].shape[0],1))\n",
    "        Xtest[tasks] = np.append(all_ones,Xtest[tasks],1);\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    local_lam_range = [10, 1.0, .1, .01, .001, .0001, .00001, .000001]\n",
    "    local_max_iter_range = [1, 5, 10]\n",
    "    local_tol_range = [.1, .01, .001, .0001]\n",
    "    local_results[:,t] = run_local(Xtrain,Ytrain, Xtest, Ytest, \n",
    "                                   cv = cv, lam_range = local_lam_range, \n",
    "                                   max_iter_range = local_max_iter_range, tol_range = local_tol_range).squeeze()\n",
    "    \n",
    "    global_lam_range = [10, 1.0, .1, .01, .001, .0001, .00001, .000001]\n",
    "    global_max_iter_range = [1, 5, 10]\n",
    "    global_tol_range = [.1, .01, .001, .0001]\n",
    "    global_results[:,t] = run_global(Xtrain,Ytrain, Xtest, Ytest, \n",
    "                                   cv = cv, lam_range = global_lam_range, \n",
    "                                   max_iter_range = global_max_iter_range, tol_range = global_tol_range).squeeze()\n",
    "    \n",
    "    \n",
    "    mtl_lam_range = [1.0, .1, .01, .001, .0001, .00001, .000001]\n",
    "    mtl_outer_iters_range = [5, 10, 50]\n",
    "    mtl_inner_iters_range = [1, 5, 10]\n",
    "    mtl_local_iters_range = [.5, 1.0, 2.0]\n",
    "    mtl_results[:,t] = run_mtl(Xtrain, Ytrain, Xtest, Ytest, cv = cv, lam_range = mtl_lam_range,\n",
    "                                  outer_iters_range = mtl_outer_iters_range, inner_iters_range = mtl_inner_iters_range, \n",
    "                                  local_iters_range = mtl_local_iters_range).squeeze()\n",
    "    \n",
    "\n",
    "local_results_avg = np.mean(local_results, axis = 1)\n",
    "global_results_avg = np.mean(global_results, axis = 1)\n",
    "mtl_results_avg = np.mean(mtl_results, axis = 1)\n",
    "\n",
    "print('local score:')\n",
    "print(local_results_avg)\n",
    "\n",
    "print('global score:')\n",
    "print(global_results_avg)\n",
    "\n",
    "print('mtl score:')\n",
    "print(mtl_results_avg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the results in another form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_results_avg = np.mean(local_results, axis = 0)\n",
    "global_results_avg = np.mean(global_results, axis = 0)\n",
    "mtl_results_avg = np.mean(mtl_results, axis = 0)\n",
    "\n",
    "\n",
    "print('local score:')\n",
    "print(local_results_avg)\n",
    "\n",
    "print('global score:')\n",
    "print(global_results_avg)\n",
    "\n",
    "print('mtl score:')\n",
    "print(mtl_results_avg)\n",
    "\n",
    "print('local mean and std:')\n",
    "print(np.mean(local_results_avg))\n",
    "print(np.std(local_results_avg))\n",
    "\n",
    "print('global mean and std:')\n",
    "print(np.mean(global_results_avg))\n",
    "print(np.std(global_results_avg))\n",
    "\n",
    "print('mtl mean and std:')\n",
    "print(np.mean(mtl_results_avg))\n",
    "print(np.std(mtl_results_avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
